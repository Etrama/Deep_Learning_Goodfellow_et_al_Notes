{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Norm - size of a vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.mathpix.com/snip/images/aj97mdGD6kK0EQ39kmT_p0LRinlBmmvwo7aTiW2sHUs.original.fullsize.png\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the same example as given in the link along with a small exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(9) - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4, -3, -2, -1,  0,  1,  2,  3,  4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.reshape((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4, -3, -2],\n",
       "       [-1,  0,  1],\n",
       "       [ 2,  3,  4]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.745966692414834"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.745966692414834"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So, the L1 norm just seems to be the summation of all the absolute values of the elements in a vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for any vector of any shape, we would just flatten the vector, and add the absolute values of the all the elements to get the L1 norm:    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.flatten.html<br>\n",
    "https://stackoverflow.com/questions/18777737/how-to-calculate-the-absolute-value-for-an-array-in-python<br>\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.sum.html<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_norm_calculator(vector):\n",
    "    x = vector.flatten()\n",
    "    x = np.absolute(x)\n",
    "    x = np.sum(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_norm_calculator(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(a, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_norm_calculator(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(b, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How is the above value 7? why is it not 20? Are vector norms and matrix norms calculated differently?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like we guessed right. Check out the special cases here: https://en.wikipedia.org/wiki/Matrix_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the matrix norm is basically the sum of all the elements of a column which is why it comes out to 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's extend this to the L2 Norm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.745966692414834"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(a,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.3484692283495345"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(b,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_norm_calculator_vec(vector):\n",
    "    x = vector.flatten()\n",
    "    x = np.absolute(x)* np.absolute(x) #Elementwise product\n",
    "    x = np.sum(x)\n",
    "    return np.sqrt(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://www.sharpsightlabs.com/blog/numpy-square-root/<br>\n",
    "https://stackoverflow.com/questions/13567345/how-to-calculate-the-sum-of-all-columns-of-a-2d-numpy-array-efficiently<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.745966692414834"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_norm_calculator_vec(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_norm_calculator_matrix(matrix):\n",
    "    x = np.absolute(matrix) * np.absolute(matrix) #elementwise product\n",
    "    x = x.sum(axis=0)\n",
    "    x = np.sqrt(x)\n",
    "    return max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.58257569495584"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_norm_calculator_matrix(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If np.sqrt(21) was the answer then the above is the right answer. It seems like we were fooled again by the definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://math.stackexchange.com/questions/3044929/l2-norm-of-a-matrix-is-this-statement-true<br>\n",
    "Seems like a complicated story, remains to be seen if we will actually need it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The grand takeaway here is calculation of L<sup>p</sup> norms for vectors is trivially simple based on the formula and the two functions we just went over, the matrix norm however, is defined differently and will need to be handled as such."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In general, a norm is function which satisfies the following properties:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.mathpix.com/snip/images/lRDkl4gvC9MMUmfq8usGICW4CwS_IQ6OEx_CRYhNlr4.original.fullsize.png\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The norm is zero when the input to the norm is zero, trivial really, when you think about completely zero vectors.\n",
    "2. The norm of the addition of two vectors will be less than or equal to the sum of the individual norms of these vectors.\n",
    "3. The norm of any real constant multiplied by the input vector will be the same as the product of the absolute value of this constant and the norm of the input vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 and L1 norms are very frequently used in ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 norm is often mentioned without the subsccript 2. \n",
    "### L2 norm is used to measure the size of a vector by using- x<sup>T</sup>x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The squared L2 norm is also quite frequently used. <br>This is because the squared L2 norm is simply the sum of the squares of the individual elements (no needs for absolute either, since the square of a negative number will be the same as the square of a positive number. <br>Therefore:<br>\n",
    "squared_L2_norm_of_vector(x) = x<sub>1</sub><sup>2</sup> + x<sub>2</sub><sup>2</sup> + x<sub>3</sub><sup>2</sup> + ..... + x<sub>n</sub><sup>2</sup><br>\n",
    "squared_L2_norm_of_vector = F<br>\n",
    "Derivative of F(x) wrt x<sub>1</sub> = 2X<sub>1</sub><br>\n",
    "Derivative of F(x) wrt x<sub>2</sub> = 2X<sub>2</sub><br>\n",
    "......<br>\n",
    "Dervative of F(x) wrt x<sub>n</sub> = 2X<sub>n</sub><br>\n",
    "\n",
    "The partial derivatives depend only on the corresponding element of x, whereas for the non-squared L2 norm they depend on the entire vector.\n",
    "\n",
    "L2_norm_of_vector(x) = np.sqrt(x<sub>1</sub><sup>2</sup> + x<sub>2</sub><sup>2</sup> + x<sub>3</sub><sup>2</sup> + ..... + x<sub>n</sub><sup>2</sup>)<br>\n",
    "L2_norm_of_vector = G<br>\n",
    "Derivative of G(x) wrt x<sub>1</sub> = 0.5 . G(x) ^ (-1/2) . 2 . x<sub>1</sub><br>\n",
    "Derivative of G(x) wrt x<sub>1</sub> = 0.5 . 2 . x<sub>1</sub> . (np.sqrt(x<sub>1</sub><sup>2</sup> + x<sub>2</sub><sup>2</sup> + x<sub>3</sub><sup>2</sup> + ..... + x<sub>n</sub><sup>2</sup>)) ^ (-1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The squared L2 norm grows very slowly near the origin since the square of a number less than 1 will be less than the original number itself. In these cases it is better to use the L1 norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010000000000000002"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0.1\n",
    "math.pow(a,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1 norm is often used as a substitute to count the number of non zero entries in a vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max Norm - simply the largest element in the vector:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.mathpix.com/snip/images/gDZeq2S8-Zvh1c6go5C_JDUeR-Mx7IFSWmMSPa3PX60.original.fullsize.png\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Frobenius norm is analogous to the L2 norm and is used to measure the size of a vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.mathpix.com/snip/images/2HvnO-qWnslr46ZC-k28_0jMVtThgaTSGRa8mRCRDc4.original.fullsize.png\"><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4, -3, -2],\n",
       "       [-1,  0,  1],\n",
       "       [ 2,  3,  4]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.745966692414834"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(b, 'fro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4, -3, -2, -1,  0,  1,  2,  3,  4])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(9) - 4\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid norm order for vectors.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[1;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[0;32m   2289\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2290\u001b[1;33m                 \u001b[0mord\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2291\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: must be str, not int",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-038cedf71331>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[1;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[0;32m   2290\u001b[0m                 \u001b[0mord\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2291\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2292\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid norm order for vectors.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2293\u001b[0m             \u001b[0mabsx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2294\u001b[0m             \u001b[0mabsx\u001b[0m \u001b[1;33m**=\u001b[0m \u001b[0mord\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid norm order for vectors."
     ]
    }
   ],
   "source": [
    "np.linalg.norm(a, 'fro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### looks like 'fro' doesnt work for 1D vectors. Why arent we using the .shape argument for all of these? Is it somehow less efficient? I guess it would just traverse an array and increase the count right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.mathpix.com/snip/images/CXaVFkAMnDbaJQ-dzW7Up1rrugQEmfZKx0HM66IkaQo.original.fullsize.png\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Special kinds of Matrices and Vectors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagonal Matrix: All the non-diagonal elements are zero, for example in the identity matrix. A matrix where only the diagonal elements are non-zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.eye(4,4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is to find the diagonal of a matrix.\n",
    "np.diagonal(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://docs.scipy.org/doc/numpy/reference/generated/numpy.diagonal.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Diagonal matrices are computationaly efficient.<br>\n",
    "diag(v)x = Hadamard_product(v,x)<br>\n",
    "2. The inverse only exists if the diagonal elements are non-zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symmetric Matrix: A matrix that is equal to its own transpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit Vector : A vector with unit norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x and y are orthogonal if x<sup>T</sup>y = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that for non-zero norm, x and y are at 90 degrees to each other.<br>\n",
    "If the vectors are not only orthogonal, but also have unit norm, then we call them <b>Orthonormal</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the book:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.mathpix.com/snip/images/WtDM_cHOcsQN_hTraMXVDrZMQqaEaemOvj39RGtnA68.original.fullsize.png\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing mathjax\n",
    "<script src=\"https://polyfill.io/v3/polyfill.min.js?features=es6\"></script>\n",
    "<script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>\n",
    "\n",
    "Example (trial):\n",
    "When $$(a \\ne 0),$$ there are two solutions to \\(ax^2 + bx + c = 0\\) and they are\n",
    "$$x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}.$$\n",
    "(end of trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigendecomposition:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to prime factorization of integers, matrices can be decomposed to show some of their functional properties that are not obvious from their representation as an array of elements. One of these ways of representation is called <b>Eigendecomposition</b>, in which we decompose a matrix into <b>eigenvalues</b> and <b>eigenvectors</b> ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://docs.mathjax.org/en/latest/basic/mathematics.html<br>\n",
    "https://oeis.org/wiki/List_of_LaTeX_mathematical_symbols<br>\n",
    "https://tex.stackexchange.com/questions/327844/real-number-symbol-r-not-working<br>\n",
    "https://tex.stackexchange.com/questions/52276/inline-equation-in-latex-with-text<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\boldsymbol{A} \\boldsymbol{v}=\\lambda \\boldsymbol{v}$$\n",
    "where, <br>\n",
    "$$\\boldsymbol{A} = \\text{Square matrix A, mutiplication by A only alters the scale of v}$$<br>\n",
    "$$\\boldsymbol{v} = \\text{Eigenvector of Square matrix A}$$<br>\n",
    "$$\\lambda = \\text{Eigenvalue of the eigenvector}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the book:<img src=\"https://cdn.mathpix.com/snip/images/dJePmPkLeEQkTLqtcg16K6Cz9Yu7--99LvcQXU2FUn4.original.fullsize.png\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.e from above, for $$s \\in \\mathbb{R}, s \\neq 0,$$\n",
    "$$\\boldsymbol{A} \\boldsymbol{s}=\\lambda \\boldsymbol{s}$$\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\boldsymbol{A} \\text{ has n linearly dependent eigenvectors:}\\left\\{\\boldsymbol{v}^{(1)}, \\ldots,\\right., \\boldsymbol{v}^{(n)}\\} \\text{ with eigenvalues: } \\left\\{\\lambda_{1}, \\ldots, \\lambda_{n}\\right\\}, \\text{ then we can concatenate (just place them side by side, nothing special) all the eigenvectors to form a matrix } \\boldsymbol{V} \\text{ and we can do the same for } \\lambda, i.e: $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boldsymbol{V}=\\left[\\boldsymbol{v}^{(1)}, \\ldots\\right.,\\boldsymbol{v}^{(n)}]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boldsymbol{\\lambda}=\\left[\\lambda_{1}, \\ldots,\\right., \\lambda_{n}]^{\\top}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>eigendecomposition</b> of $\\boldsymbol{A}$ is given by:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boldsymbol{A}=\\boldsymbol{V} \\operatorname{diag}(\\boldsymbol{\\lambda}) \\boldsymbol{V}^{-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Didn't really undestand how we ended up with the above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.mathpix.com/snip/images/8vTLc7NdfONC5iK_bFgQ0AZ_DCsN1tsc9hHloYHj1Ys.original.fullsize.png\"><br>\n",
    "<img src=\"https://cdn.mathpix.com/snip/images/CaG7TiktZTejvokkdVoHb-rKfL6hTpXrIJR5Q0icEII.original.fullsize.png\"><br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doubt:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\boldsymbol{A} \\boldsymbol{v}=\\lambda \\boldsymbol{v}$$\n",
    "We replace $\\boldsymbol{v}$  by $\\boldsymbol{Q}$, and $\\lambda$ by its diagonal version????? Ordering seems off\n",
    "$$\\boldsymbol{A} \\boldsymbol{Q}=\\boldsymbol{Q} \\Lambda$$\n",
    "<br>\n",
    "I'm still not clear on how we went from $\\boldsymbol{A} \\boldsymbol{v}=\\lambda \\boldsymbol{v}$ to $\\boldsymbol{A} \\boldsymbol{Q}=\\boldsymbol{Q} \\Lambda$\n",
    "\n",
    "The second step is clear enough, multiply by the inverse matrix on both the sides (Q inverse), and since the inverse of a symmetric matrix is the same as its transpose, we get the result below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For real symmetric matrices:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boldsymbol{A}=\\boldsymbol{Q} \\boldsymbol{\\Lambda} \\boldsymbol{Q}^{\\top}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some easy pickings:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A matrix whose eigenvalues are all positive is called <b>positive definite</b>\n",
    "* A matrix whose eigenvalues are all positive or zero is called <b>positive semidefinite</b>\n",
    "* A matrix whose eigenvalues are all negative is called <b>negative definite</b>\n",
    "* A matrix whose eigenvalues are all negative or zero is called <b>negative semidefinite</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For positive semidefinite matrices: <br>\n",
    "For all input x, x<sup>T</sup>Ax will be greater than or equal to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive Definite matrices:<br>\n",
    "For all input x, x<sup>T</sup>Ax will be greater than 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singular Value Decomposition:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Alternate way to factorize a matrix rather than doing it with eigenvalues and eigenvectors.\n",
    "* Generally more applicable. Every matrix has an SVD, every matrix does not have an eigenvalue and eigenvector.(non-square matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A = V . diag(&lambda;) . V<sup>-1</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need an intuitive way to think about Eigenvalues and eigenvectors, this equation aint gonna cut it.<br>\n",
    "1. https://math.stackexchange.com/questions/243533/how-to-intuitively-understand-eigenvalue-and-eigenvector\n",
    "2. http://setosa.io/ev/eigenvectors-and-eigenvalues/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD says: A = U . D . V<sup>T</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* U (left singular vector) and V (right singular vector) need to be orthogonal matrices (U<sup>T</sup> = U<sup>-1</sup>, same for V)\n",
    "* D (singular values) need not be square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some practice with eigenvalues and SVD:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.physics.utah.edu/~detar/lessons/python/numpy_eigen/node1.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lhs - left hand side, \n",
    "rhs - right hand side\n",
    "\n",
    "We are trying to get this result:\n",
    "$$\\boldsymbol{A} \\boldsymbol{v}=\\lambda \\boldsymbol{v}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a few matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "B = np.array([[9,9,9],[9,9,9],[9,9,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, vectors = np.linalg.eig(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.61168440e+01, -1.11684397e+00, -9.75918483e-16])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.23197069, -0.78583024,  0.40824829],\n",
       "       [-0.52532209, -0.08675134, -0.81649658],\n",
       "       [-0.8186735 ,  0.61232756,  0.40824829]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhs = np.dot(A,vectors)\n",
    "rhs = np.dot(values,vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.73863537e+00,  8.77649763e-01, -3.88578059e-16],\n",
       "       [-8.46653421e+00,  9.68877101e-02, -3.33066907e-16],\n",
       "       [-1.31944331e+01, -6.83874343e-01, -7.21644966e-16]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -3.15193256, -12.56821563,   7.49157328])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mistake we made here was to use vector multplication instead of matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhs = A * vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.23197069, -1.57166048,  1.22474487],\n",
       "       [-2.10128837, -0.4337567 , -4.89897949],\n",
       "       [-5.7307145 ,  4.89862048,  3.67423461]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhs = values * vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.73863537e+00,  8.77649763e-01, -3.98417052e-16],\n",
       "       [-8.46653421e+00,  9.68877101e-02,  7.96834105e-16],\n",
       "       [-1.31944331e+01, -6.83874343e-01, -3.98417052e-16]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lhs == rhs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait, what?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, let's break it down:\n",
    "A - 3x3 matrix<br>\n",
    "vectors - 3x3 matrix<br>\n",
    "values - 3x1 or 1x3 (depends- (3,)) matrix<br>\n",
    "\n",
    "A x vectors - 3x3 matrix<br>\n",
    "values x vectors - NOT 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array([values,values,values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.61168440e+01, -1.11684397e+00, -9.75918483e-16],\n",
       "       [ 1.61168440e+01, -1.11684397e+00, -9.75918483e-16],\n",
       "       [ 1.61168440e+01, -1.11684397e+00, -9.75918483e-16]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.73863537e+00,  8.77649763e-01, -3.98417052e-16],\n",
       "       [-8.46653421e+00,  9.68877101e-02,  7.96834105e-16],\n",
       "       [-1.31944331e+01, -6.83874343e-01, -3.98417052e-16]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values * vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like we didnt need to this sort of broadcasting, compare the above to the rhs and we see why"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, comparing the old lhs and new rhs it seems like we need to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "values, vectors = np.linalg.eig(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhs = np.dot(A,vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.73863537e+00,  8.77649763e-01, -3.88578059e-16],\n",
       "       [-8.46653421e+00,  9.68877101e-02, -3.33066907e-16],\n",
       "       [-1.31944331e+01, -6.83874343e-01, -7.21644966e-16]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhs = values*vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.73863537e+00,  8.77649763e-01, -3.98417052e-16],\n",
       "       [-8.46653421e+00,  9.68877101e-02,  7.96834105e-16],\n",
       "       [-1.31944331e+01, -6.83874343e-01, -3.98417052e-16]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lhs == rhs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weird - columns 1 and 2 seem pretty much the same to me in the lhs and rhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhs = np.multiply(values,vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.73863537e+00,  8.77649763e-01, -3.98417052e-16],\n",
       "       [-8.46653421e+00,  9.68877101e-02,  7.96834105e-16],\n",
       "       [-1.31944331e+01, -6.83874343e-01, -3.98417052e-16]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is befuddling. Is this one of those matrices which does not have an eigen decomposition?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://math.stackexchange.com/questions/651934/invertibility-eigenvalues-and-singular-values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like all sqaure matrices with a non-zero determinant should be invertible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.51619735392994e-16"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.det(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, such luck, much wow, just had to pick a matrix with a zero determinant and doubt everything I just learned.<br> Anyway, we just need to pick a matrix with a non-zero determinant and we should be fine.<br>It's still pretty interesting that 2 of the columns turn out to be the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-11.999999999999957"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1,20,3],[4,15,6],[7,8,9]])\n",
    "np.linalg.det(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we should be set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, vectors = np.linalg.eig(A)\n",
    "#values and vectors in alphabetical order - FYI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.57317948, -0.51726151,  0.94408203])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.57506513,  0.79245773, -0.69702376],\n",
       "       [ 0.59331453,  0.03125058, -0.10446092],\n",
       "       [ 0.56327432, -0.60912572,  0.70939819]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhs = np.dot(A,vectors)\n",
    "rhs = values*vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.13117868, -0.40990788, -0.6580476 ],\n",
       "       [14.57962441, -0.01616472, -0.09861968],\n",
       "       [13.84144107,  0.31507729,  0.66973009]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.13117868, -0.40990788, -0.6580476 ],\n",
       "       [14.57962441, -0.01616472, -0.09861968],\n",
       "       [13.84144107,  0.31507729,  0.66973009]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lhs == rhs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, a couple of takeaways:<br>\n",
    "1. the lhs==rhs doesnt seems to work\n",
    "2. we use a dot product on one side and * on the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(lhs,rhs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we dealt with the first takeaway. Use np.allclose() to compare numpy arrays. <br>https://docs.scipy.org/doc/numpy/reference/generated/numpy.allclose.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigating the second takeaway:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,1],[1,1]])\n",
    "B = A + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2],\n",
       "       [2, 2]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2],\n",
       "       [2, 2]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A*B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 4],\n",
       "       [4, 4]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2],\n",
       "       [2, 2]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.13117868, -0.40990788, -0.6580476 ],\n",
       "       [14.57962441, -0.01616472, -0.09861968],\n",
       "       [13.84144107,  0.31507729,  0.66973009]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1,20,3],[4,15,6],[7,8,9]])\n",
    "np.dot(A,vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I see now:<br>\n",
    "\\* - Hadamard Product<br>\n",
    "np.dot() - row+column song product - https://www.youtube.com/watch?v=BGbiHdKHG7o - actually heard Jeremy mention it while doing Fast AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so the lhs makes sense now - we are supposed to use np.dot() for the lhs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the rhs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 14.35605708,  18.88197677, -16.40432616])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(values,vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We took the dot product of a 1x3 matrix and a 3x3 matrix to get a 1x3 matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we need to broadcast the multiplication by column, the values array has 3 columns and each column must be multiplied down like mentioned in one of the links. So we need the inplace product / Hadamard product here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.13117868, -0.40990788, -0.6580476 ],\n",
       "       [14.57962441, -0.01616472, -0.09861968],\n",
       "       [13.84144107,  0.31507729,  0.66973009]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values*vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, all is right with the world. Moving on.....<br>\n",
    "We still need some physical intuition about eigenvalues and vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
